{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc326d2c-d823-4140-9e75-5ddbf5425459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --quiet pytorch_lightning\n",
    "# !pip install --quiet transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1b6acda-308b-4fb2-863c-f9afed9377e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "text = \"ngày mười tháng mười một một chín chín ba tháng mười\"\n",
    "\n",
    "# pattern to find 'mười' right after 'tháng'\n",
    "pattern = r'(?<=tháng )\\bmười\\b'\n",
    "\n",
    "match = re.search(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd05d463-f9b2-4096-a3f0-99fa211398a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngày hai mươi ba tháng mười một năm chín chín tư năm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def change_string(text):\n",
    "    pattern = r'\\btháng một\\b'\n",
    "    new_text = re.sub(r'\\btháng một\\b', 'tháng mười', text)\n",
    "    return new_text\n",
    "\n",
    "# Test the function\n",
    "text = 'ngày hai mươi ba tháng một một năm chín chín tư năm'\n",
    "print(change_string(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22bc867d-ae8d-4a55-9070-0ca2d03f4541",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4757d8fa-0a3a-4a36-acb2-5ead1160c839",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 10), match='tháng mười'>\n",
      "True\n",
      "None\n",
      "False\n",
      "None\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def check_string(text):\n",
    "    pattern = r'\\btháng mười\\b(?=.*\\b\\w+\\b)'\n",
    "    match = re.search(pattern, text)\n",
    "    print(match)\n",
    "    return match is not None\n",
    "\n",
    "# Test the function\n",
    "print(check_string('tháng mười năm hai không'))  # True\n",
    "print(check_string('tháng mười'))  # False\n",
    "print(check_string('tháng hai năm hai không'))  # False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "891684f8-f19b-42e7-b5b3-1f2c126680e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'một một chín chín ba tháng mười'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[match.span()[1] + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a82c511e-b764-474d-8265-e1985b5a4a6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import textwrap\n",
    "\n",
    "from torch.utils.data import Dataset,DataLoader, random_split\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from transformers import(\n",
    "    AdamW,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee13b38-d892-4924-9c29-5cf47a331c99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0948d8f6-a36e-42a7-92a0-5db1001b048a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_device_and_set_seed(seed):\n",
    "    \"\"\" Set all seeds to make results reproducible \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    np.random.seed(seed)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    return device\n",
    "    \n",
    "SEED = 123\n",
    "device = get_device_and_set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b08bd429-b4d4-4051-9981-f4229782c766",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(36096, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(36096, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(36096, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"VietAI/vit5-base\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dfadf22-5e71-4687-98b2-8c93a8f55d63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c5480c2-96da-49f4-aa25-78e7dc3322a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"VietAI/vit5-base\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f66f0df-fb15-46ac-ad1c-9262f223f96a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = tokenizer(\n",
    "        'tôi thích bạn', max_length=256, truncation=True, padding=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22780b21-ffdc-42ef-83a4-e00a30c05323",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [671, 1470, 1113, 1], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f31dcfd-d816-4484-a673-cac97e852e76",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "492c52cf-2cdb-4dec-86db-df658dbb653c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = './UIT-ViNames-Dataset/UIT-ViNames/Train.csv'\n",
    "val_path = './UIT-ViNames-Dataset/UIT-ViNames/Val.csv'\n",
    "test_path = './UIT-ViNames-Dataset/UIT-ViNames/Test.csv'\n",
    "null_path = './UIT-ViNames-Dataset/UIT-ViNames/Null.csv'\n",
    "null_path_1 = './UIT-ViNames-Dataset/UIT-ViNames/Null_1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c03f8e78-ede8-421d-bf08-53b1e5f5b1ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full_Names</th>\n",
       "      <th>Gender</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ngô xuân tùng</td>\n",
       "      <td>1</td>\n",
       "      <td>ngô xuân tùng một à</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bùi dương thảo vy</td>\n",
       "      <td>0</td>\n",
       "      <td>bùi dương thảo vy rồi vầng anh cho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lưu thế huy</td>\n",
       "      <td>1</td>\n",
       "      <td>ừ một ơ lưu thế huy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nguyễn thị vân</td>\n",
       "      <td>0</td>\n",
       "      <td>ơ ờ nguyễn thị vân là có cái</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dương minh long</td>\n",
       "      <td>1</td>\n",
       "      <td>chị ạ năm mình một dương minh long</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Full_Names  Gender                            sentence\n",
       "0      ngô xuân tùng       1                 ngô xuân tùng một à\n",
       "1  bùi dương thảo vy       0  bùi dương thảo vy rồi vầng anh cho\n",
       "2        lưu thế huy       1                 ừ một ơ lưu thế huy\n",
       "3     nguyễn thị vân       0        ơ ờ nguyễn thị vân là có cái\n",
       "4    dương minh long       1  chị ạ năm mình một dương minh long"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_path)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b035ec2f-7c22-498e-8df3-42a5cd10795c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(val_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "null_df = pd.read_csv(null_path)\n",
    "null_df_1 = pd.read_csv(null_path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d25bdce-6c52-4c7a-9e6d-8b97c9dc15dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full_Names</th>\n",
       "      <th>Gender</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ngô xuân tùng</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ngô xuân tùng một à</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bùi dương thảo vy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bùi dương thảo vy rồi vầng anh cho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lưu thế huy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ừ một ơ lưu thế huy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nguyễn thị vân</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ơ ờ nguyễn thị vân là có cái</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dương minh long</td>\n",
       "      <td>1.0</td>\n",
       "      <td>chị ạ năm mình một dương minh long</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Full_Names  Gender                            sentence\n",
       "0      ngô xuân tùng     1.0                 ngô xuân tùng một à\n",
       "1  bùi dương thảo vy     0.0  bùi dương thảo vy rồi vầng anh cho\n",
       "2        lưu thế huy     1.0                 ừ một ơ lưu thế huy\n",
       "3     nguyễn thị vân     0.0        ơ ờ nguyễn thị vân là có cái\n",
       "4    dương minh long     1.0  chị ạ năm mình một dương minh long"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([train_df, null_df, null_df_1], ignore_index = False)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d60cba40-41cc-440d-83f3-93eeb6fff076",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full_Names</th>\n",
       "      <th>Gender</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dạ vâng ạ em xin phép có thể nói chuyện với a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ờ dạ vâng ạ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a lô dạ vâng em chào anh ạ anh cho em hỏi số m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>đó để em trao đổi với các chuyên gia của bên e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dạ rồi ok em cảm ơn em chào anh ạ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Full_Names  Gender                                           sentence\n",
       "995       None     NaN  dạ vâng ạ em xin phép có thể nói chuyện với a ...\n",
       "996       None     NaN                                        ờ dạ vâng ạ\n",
       "997       None     NaN  a lô dạ vâng em chào anh ạ anh cho em hỏi số m...\n",
       "998       None     NaN  đó để em trao đổi với các chuyên gia của bên e...\n",
       "999       None     NaN                  dạ rồi ok em cảm ơn em chào anh ạ"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cd1d3bd-42f4-4f86-9508-e31b5e09264b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"inputs\"], max_length=256, truncation=True, padding=True\n",
    "    )\n",
    "    \n",
    "    \n",
    "    labels = tokenizer(\n",
    "        examples[\"labels\"], max_length=256, truncation=True, padding=True\n",
    "    )\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    model_inputs['input_ids'] = model_inputs['input_ids']\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5841ab54-9900-42fa-886c-b97ea4d7bbc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a87064e69b74693bf31baf852c27786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758aac10b50a48fdb3a4c1e0117e8214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e433f06502c424596b72c63dd76ccde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d246e89c0e2f41a9b7339835f53c1e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae5018313b5949008c0e87873be9512b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d89386e87e245fba8e2ec88140a4809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1683ac59774e51b2f7642c8d839881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd333d40694d46b9963bc5ca7b63fb49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_obj = {'inputs': train_df['sentence'], 'labels': train_df['Full_Names']}\n",
    "dataset = Dataset.from_dict(dict_obj)\n",
    "train_data = dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5a1fd85-c7e6-4361-a833-dcd4f6ec59f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68f6cc27f0e4ee2af4871f27915484c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee5d5c878434e1fb9b4b0a4f8110d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c9a38d26004a388efc4fe2c184d8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00bf0ae146b40909eee89e523992f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b2d34ccc824ed384319cee08b9bc5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1f129fa880448a91d88d4926b52161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411563ab536744fbb41a6106443feeab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df803957c2a54360a72bfa7c233ec06a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_obj = {'inputs': val_df['sentence'], 'labels': val_df['Full_Names']}\n",
    "dataset = Dataset.from_dict(dict_obj)\n",
    "val_data = dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77f5c5c7-23dd-4184-b398-89036d6894d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d492f815fcf4caebdeeef7a10f71e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d3ad152e204986b635dcbc89c66258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e51932bb4445669637db6060ea863b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cdec538cc34e35a5984cf6167137ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac0a160c2e34785921829a38151241a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864c30e7f14b44069decdb38129084f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72168fafa58d416691b4c14736f71e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0043f1b9b4c41eeb393a6148059a651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_obj = {'inputs': test_df['sentence'], 'labels': test_df['Full_Names']}\n",
    "dataset = Dataset.from_dict(dict_obj)\n",
    "test_data = dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66b2a68c-af31-4032-b8a9-8c0b43da4828",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': [6043, 4211, 4694, 1, 0, 0, 0, 0, 0],\n",
       " 'input_ids': [6043, 4211, 4694, 68, 536, 1, 0, 0, 0, 0, 0, 0],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "077c4f0e-b320-4c8a-9778-3cadfec4d3d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5370"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d0a1a13-56b8-46a1-8440-999995afdf8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m DataCollatorForSeq2Seq(tokenizer, model\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m training_args \u001b[38;5;241m=\u001b[39m Seq2SeqTrainingArguments(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtmp/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m                                       do_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m                                       do_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m                                       fp16\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     24\u001b[0m                                       )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\"tmp/\",\n",
    "                                      do_train=True,\n",
    "                                      do_eval=True,\n",
    "                                      evaluation_strategy='steps',\n",
    "                                      eval_steps=2475,\n",
    "                                      num_train_epochs=15,\n",
    "                                      learning_rate=1e-5,\n",
    "                                      warmup_ratio=0.05,\n",
    "                                      weight_decay=0.01,\n",
    "                                      per_device_train_batch_size=4,\n",
    "                                      per_device_eval_batch_size=4,\n",
    "                                      logging_dir='./log',\n",
    "                                      group_by_length=True,\n",
    "                                      load_best_model_at_end=True,\n",
    "                                      save_steps=2475,\n",
    "                                      save_total_limit=1,\n",
    "                                      #eval_steps=1,\n",
    "                                      #evaluation_strategy=\"steps\",\n",
    "                                      # evaluation_strategy=\"no\",\n",
    "                                      fp16=True,\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d28878-92c2-46d7-b44f-09baeb753a52",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b8867e-c435-400e-8eeb-1c709b372255",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 19795\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37125\n",
      "  Number of trainable parameters = 225950976\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16133' max='37125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16133/37125 2:58:02 < 3:51:41, 1.51 it/s, Epoch 6.52/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2475</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.010165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4950</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.007088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7425</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.005444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.005090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12375</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.006284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14850</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.007116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2686\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to tmp/checkpoint-2475\n",
      "Configuration saved in tmp/checkpoint-2475/config.json\n",
      "Configuration saved in tmp/checkpoint-2475/generation_config.json\n",
      "Model weights saved in tmp/checkpoint-2475/pytorch_model.bin\n",
      "Deleting older checkpoint [tmp/checkpoint-21150] due to args.save_total_limit\n",
      "Deleting older checkpoint [tmp/checkpoint-22325] due to args.save_total_limit\n",
      "Deleting older checkpoint [tmp/checkpoint-23500] due to args.save_total_limit\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2686\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to tmp/checkpoint-4950\n",
      "Configuration saved in tmp/checkpoint-4950/config.json\n",
      "Configuration saved in tmp/checkpoint-4950/generation_config.json\n",
      "Model weights saved in tmp/checkpoint-4950/pytorch_model.bin\n",
      "Deleting older checkpoint [tmp/checkpoint-2475] due to args.save_total_limit\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2686\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to tmp/checkpoint-7425\n",
      "Configuration saved in tmp/checkpoint-7425/config.json\n",
      "Configuration saved in tmp/checkpoint-7425/generation_config.json\n",
      "Model weights saved in tmp/checkpoint-7425/pytorch_model.bin\n",
      "Deleting older checkpoint [tmp/checkpoint-4950] due to args.save_total_limit\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2686\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to tmp/checkpoint-9900\n",
      "Configuration saved in tmp/checkpoint-9900/config.json\n",
      "Configuration saved in tmp/checkpoint-9900/generation_config.json\n",
      "Model weights saved in tmp/checkpoint-9900/pytorch_model.bin\n",
      "Deleting older checkpoint [tmp/checkpoint-7425] due to args.save_total_limit\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2686\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to tmp/checkpoint-12375\n",
      "Configuration saved in tmp/checkpoint-12375/config.json\n",
      "Configuration saved in tmp/checkpoint-12375/generation_config.json\n",
      "Model weights saved in tmp/checkpoint-12375/pytorch_model.bin\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2686\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to tmp/checkpoint-14850\n",
      "Configuration saved in tmp/checkpoint-14850/config.json\n",
      "Configuration saved in tmp/checkpoint-14850/generation_config.json\n",
      "Model weights saved in tmp/checkpoint-14850/pytorch_model.bin\n",
      "Deleting older checkpoint [tmp/checkpoint-12375] due to args.save_total_limit\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f05861b6-a5cb-411f-819f-8ef5e1c0497e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c58c6b-e88d-46bb-97b4-a518212919f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 18795\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 35250\n",
      "  Number of trainable parameters = 225950976\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14255' max='35250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14255/35250 1:56:44 < 2:51:58, 2.03 it/s, Epoch 12.13/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.092900</td>\n",
       "      <td>0.008796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.005408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.005494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.005760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.004866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.004718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.007651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.004296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.005472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.006687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.004674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.007326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2686\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to tmp/checkpoint-1175\n",
      "Configuration saved in tmp/checkpoint-1175/config.json\n",
      "Configuration saved in tmp/checkpoint-1175/generation_config.json\n",
      "Model weights saved in tmp/checkpoint-1175/pytorch_model.bin\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2686\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to tmp/checkpoint-2350\n",
      "Configuration saved in tmp/checkpoint-2350/config.json\n",
      "Configuration saved in tmp/checkpoint-2350/generation_config.json\n",
      "Model weights saved in tmp/checkpoint-2350/pytorch_model.bin\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2686\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to tmp/checkpoint-3525\n",
      "Configuration saved in tmp/checkpoint-3525/config.json\n",
      "Configuration saved in tmp/checkpoint-3525/generation_config.json\n",
      "Model weights saved in tmp/checkpoint-3525/pytorch_model.bin\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2686\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to tmp/checkpoint-4700\n",
      "Configuration saved in tmp/checkpoint-4700/config.json\n",
      "Configuration saved in tmp/checkpoint-4700/generation_config.json\n",
      "Model weights saved in tmp/checkpoint-4700/pytorch_model.bin\n",
      "Deleting older checkpoint [tmp/checkpoint-1175] due to args.save_total_limit\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2686\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to tmp/checkpoint-5875\n",
      "Configuration saved in tmp/checkpoint-5875/config.json\n",
      "Configuration saved in tmp/checkpoint-5875/generation_config.json\n",
      "Model weights saved in tmp/checkpoint-5875/pytorch_model.bin\n",
      "Deleting older checkpoint [tmp/checkpoint-2350] due to args.save_total_limit\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2686\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to tmp/checkpoint-7050\n",
      "Configuration saved in tmp/checkpoint-7050/config.json\n",
      "Configuration saved in tmp/checkpoint-7050/generation_config.json\n",
      "Model weights saved in tmp/checkpoint-7050/pytorch_model.bin\n",
      "Deleting older checkpoint [tmp/checkpoint-3525] due to args.save_total_limit\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2686\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to tmp/checkpoint-8225\n",
      "Configuration saved in tmp/checkpoint-8225/config.json\n",
      "Configuration saved in tmp/checkpoint-8225/generation_config.json\n",
      "Model weights saved in tmp/checkpoint-8225/pytorch_model.bin\n",
      "Deleting older checkpoint [tmp/checkpoint-4700] due to args.save_total_limit\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2686\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to tmp/checkpoint-9400\n",
      "Configuration saved in tmp/checkpoint-9400/config.json\n",
      "Configuration saved in tmp/checkpoint-9400/generation_config.json\n",
      "Model weights saved in tmp/checkpoint-9400/pytorch_model.bin\n",
      "Deleting older checkpoint [tmp/checkpoint-5875] due to args.save_total_limit\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2686\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to tmp/checkpoint-10575\n",
      "Configuration saved in tmp/checkpoint-10575/config.json\n",
      "Configuration saved in tmp/checkpoint-10575/generation_config.json\n",
      "Model weights saved in tmp/checkpoint-10575/pytorch_model.bin\n",
      "Deleting older checkpoint [tmp/checkpoint-7050] due to args.save_total_limit\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2686\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to tmp/checkpoint-11750\n",
      "Configuration saved in tmp/checkpoint-11750/config.json\n",
      "Configuration saved in tmp/checkpoint-11750/generation_config.json\n",
      "Model weights saved in tmp/checkpoint-11750/pytorch_model.bin\n",
      "Deleting older checkpoint [tmp/checkpoint-8225] due to args.save_total_limit\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2686\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to tmp/checkpoint-12925\n",
      "Configuration saved in tmp/checkpoint-12925/config.json\n",
      "Configuration saved in tmp/checkpoint-12925/generation_config.json\n",
      "Model weights saved in tmp/checkpoint-12925/pytorch_model.bin\n",
      "Deleting older checkpoint [tmp/checkpoint-9400] due to args.save_total_limit\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2686\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to tmp/checkpoint-14100\n",
      "Configuration saved in tmp/checkpoint-14100/config.json\n",
      "Configuration saved in tmp/checkpoint-14100/generation_config.json\n",
      "Model weights saved in tmp/checkpoint-14100/pytorch_model.bin\n",
      "Deleting older checkpoint [tmp/checkpoint-10575] due to args.save_total_limit\n",
      "/data2/nghiatl/anaconda3/envs/SEO/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370775cc-b658-4e45-90ee-e53959d5688c",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "251422d9-884a-418a-93f9-89c2e6db0b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/nghiatl/.tmp/ipykernel_253278/2721381364.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"rouge\")\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55c24e3d-b452-4901-8ef6-acddfb6d995d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(36096, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(36096, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(36096, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./tmp/checkpoint-7425\")\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "409e71cb-e4fc-427c-84ba-f5a7fa18de80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d115eb4-8da6-4cc4-8b1e-98d584710793",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.9988018200762616, recall=0.998607608406491, fmeasure=0.9986347304154567), mid=Score(precision=0.9993805976766871, recall=0.9992200939966306, fmeasure=0.9992122872988795), high=Score(precision=0.999738926576217, recall=0.999624013478762, fmeasure=0.9995694423257271)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.9981314400993173, recall=0.9978736809435135, fmeasure=0.9978791822185674), mid=Score(precision=0.9989075108628183, recall=0.9987212911235258, fmeasure=0.9986936873389385), high=Score(precision=0.9995065952824334, recall=0.9993792675356922, fmeasure=0.9992694402121775)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.9988835018178597, recall=0.9986260973663208, fmeasure=0.9987033673961049), mid=Score(precision=0.9993805976766871, recall=0.9992294049835948, fmeasure=0.9992270898974809), high=Score(precision=0.9997396027312231, recall=0.9996311519021017, fmeasure=0.9995801538881147)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.9988361266294227, recall=0.9986207324643078, fmeasure=0.9986899167199446), mid=Score(precision=0.9993843664095062, recall=0.9992147734326506, fmeasure=0.9992268191150873), high=Score(precision=0.9997438370133901, recall=0.9996304203245544, fmeasure=0.9995735406740994))}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tqdm\n",
    "import torch \n",
    "import numpy as np\n",
    "metrics = load_metric('rouge')\n",
    "\n",
    "max_target_length = 256\n",
    "dataloader = torch.utils.data.DataLoader(test_data, collate_fn=data_collator, batch_size=32)\n",
    "\n",
    "predictions = []\n",
    "references = []\n",
    "for i, batch in enumerate(dataloader):\n",
    "  outputs = model.generate(\n",
    "      input_ids=batch['input_ids'].to('cuda'),\n",
    "      max_length=max_target_length,\n",
    "      attention_mask=batch['attention_mask'].to('cuda'),\n",
    "  )\n",
    "  outputs = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in outputs]\n",
    "\n",
    "  labels = np.where(batch['labels'] != -100,  batch['labels'], tokenizer.pad_token_id)\n",
    "  actuals = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in labels]\n",
    "  predictions.extend(outputs)\n",
    "  references.extend(actuals)\n",
    "  metrics.add_batch(predictions=outputs, references=actuals)\n",
    "\n",
    "\n",
    "metrics.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2873f01-6ffe-4fef-be54-e50813fd251a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5341"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "correct += sum(o==a for o, a in zip(predictions, references))\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c3487f8-1c09-4524-98af-0de00cf46053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9945996275605214"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/ len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1888f79-ee5d-4932-be10-b4306c00e625",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nguyễn văn tiến'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e90c77fc-664c-44e8-857e-1b16eb7ce516",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nguyễn văn tiến'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71cec75a-de54-4d82-a4a8-c455d25ff749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a= next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c92be36-98b7-406d-ac84-5fc81bdd2113",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nguyễn văn tiến thì dạ bên không cho'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(a['input_ids'][0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "14d733d5-d3f7-4652-bf18-024def42c144",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[1337,  278,  559, 1407, 2448,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 'nguyễn ờ thảo linh'\n",
    "b = tokenizer(t, return_tensors='pt')\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "34df80a1-ea47-405e-ace9-f8127bb1530d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 1337,  278,  559, 1407, 2448,    1]], device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "      input_ids=b['input_ids'].to('cuda'),\n",
    "      max_length=max_target_length,\n",
    "      attention_mask=b['attention_mask'].to('cuda'),\n",
    "  )\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c6c29af-2c85-4598-bb58-cf8beb0745a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nguyễn ờ thảo linh'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633042a9-690a-4543-a8c0-e7fc4607c697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aea4aa-a4e8-4f12-a167-6e59e5b9c7f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SEO",
   "language": "python",
   "name": "seo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
